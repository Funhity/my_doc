find /opt/saltstack/    -path *test_v6_*/jdbc*| xargs -I {} sh -c ' sed -i s/rac-scan.xinxindai.com/192.168.31.223/g  {}'

获取svn主干下最新的分支：
export svn_address=http://192.168.38.230/YXCOD/01DEV/v6webapp_branches/v6webapp_20151016;trunk_address=`echo $svn_address|cut -d "/" -f -6` ;echo $trunk_address | { svn ls $trunk_address  --verbose |sort -n  -k 1 | grep -v "\./"  | awk '{ print $6 }' | tail -3 |xargs -I {}  sh -c 'svn log --stop-on-copy  "$svn_address"   | tail -n  10  | grep  -E "r[0-9]{5}.*" | tail -n 1| awk "{print \$5 \" \"  \$6 }" | tr -d "\n" ;echo " " {}  '  ; }  | sort -n -k1,2 | tail -n 1 | awk '{ print $3}'
 
 
==========
备份salt目录和salt服务器同步
    rsync -avz  wujunrong@192.168.38.10:/opt/     ~/salt_backup  --exclude ci/workspace --exclude walle   --exclude  ci/rsync/v6_static_rsync  --exclude  ci/rsync/webapp_static_rsync  --exclude ci/packages   --exclude ci/packages_jenkins   --exclude ci/rsync_jenkins  --exclude saltstack/salt/wujunrong/  --exclude test/  --delete-excluded   --delete
备份salt目录，把从salt服务器同步来的内容同步到svn目录下
    rsync -avh /home/wujunrong/salt_backup/    /home/wujunrong/salt-svn/salt_office_env/     --cvs-exclude --dry-run

```````日志````
   scp wujunrong@192.168.38.10:/home/wujunrong/svn/wujunrong/rsyslog.conf.client-tomcat   .
   salt '*tomcat'  state.single      file.managed  name='/etc/rsyslog.conf'   source='salt://files/rsyslog.conf.client-tomcat'  backup='minion'

   scp wujunrong@192.168.38.10:/home/wujunrong/svn/wujunrong/logrotate_tomcat.logclient    .
   salt '*tomcat'  state.single      file.managed  name='/etc/logrotate.d/logrotate_tomcat'   source='salt://files/logrotate_tomcat.logclient'  backup='minion'
============
tomcat 相关配置

   
   创建tomcat v6项目war文件部署目录
   ansible   perf_*_tomcat  -m shell  -a "mkdir  -p \`cat /etc/salt/grains|  grep tomcat_app_dir|cut -d \" \" -f 2\`  "
   或ansible perf*tomcat    -m shell  -a  "mkdir -p /opt/webserver/v6_tomcat/"
   
   安装tomcat
   ansible perf*tomcat -m copy -a "src=/root/apache-tomcat-6.0.45.tar.gz   dest=/root/"  
   ansible perf*tomcat    -m shell  -a  "tar zxf /root/apache-tomcat-6.0.45.tar.gz  -C   /opt/webserver/"
   ansible perf*tomcat    -m shell  -a  "mv    /opt/webserver/apache-tomcat-6.0.45/*    /opt/webserver/v6_tomcat/"
   

     
   从stage环境copy tomcat文件：scp root@192.168.31.50:/etc/init.d/tomcat  /root/
   ansible perf*tomcat -m copy -a "src=/root/tomcat  dest=/etc/init.d/tomcat"
   ansible perf*tomcat -m shell -a "chmod +x  /etc/init.d/tomcat"

   tomcat用户相关
   ansible perf*tomcat -m shell -a "useradd tomcat && usermod -u 1501  tomcat && chown -R tomcat:tomcat  /opt/webserver/v6_tomcat/"
   ansible perf*tomcat -m shell -a "usermod -u 1501  tomcat"
   salt *tomcat    cmd.run 'chown -R tomcat:tomcat  /opt/webserver/v6_tomcat/'
   
   配置tomcat服务器的hosts文件，获取ip地址和主机名称（另外，配置salt 域名也需要修改hosts文件）
   ansible perf*tomcat -m shell -a "ip a | grep 192 |awk '{print \$2}'  |cut -d "/" -f 1  | tr -d \"\n\" ;echo -ne ' '  ;hostname "
   ansible perf_credit01_tomcat  -m shell -a "{ ip a | grep 192 |awk '{print \$2}'  |cut -d "/" -f 1  | tr -d \"\n\" ;echo -ne ' '  ;hostname; }>>/etc/hosts"
   
   
   配置java环境和tomcat环境
   `````````````
      ansible perf*tomcat     -m copy  -a "src=/root/jdk-6u45-linux-x64-rpm.bin  dest=/root/"
      
      ansible perf_zoo*       -m shell -a  "chmod +x /root/jdk-6u45-linux-x64-rpm.bin"
      ansible perf_zoo*       -m shell -a  "/root/jdk-6u45-linux-x64-rpm.bin"
      ansible perf_zoo*       -m shell -a  "yum -y remove java-1.7.0-openjdk.x86_64"
      ansible perf*tomcat -m shell  -a  "rpm -e jdk-1.6.0_45-fcs.x86_64"
      ansible perf*tomcat -m shell  -a   "rm -fr /root/jdk-6u45-linux-amd64.rpm /root/sun*.rpm"
      ansible perf*tomcat -m shell  -a  "/root/jdk-6u45-linux-x64-rpm.bin"
   `````````````
   
   创建环境变量设置脚本（java和tomcat） vi /root/install_java_env.sh
   脚本位于服务器上                      ansible perf*tomcat -m  script -a "/root/install_java_env.sh"
   vi /root/install_java_env.sh
   #!/bin/bash
   set -e
   sudo tee /etc/profile.d/java.sh<<-'EOF'
      export JAVA_HOME=/usr/java/default
      export CATALINA_HOME=/opt/webserver/v6_tomcat/
      #export PATH=/root/apache-maven-3.2.5/bin:$PATH
   EOF
   chmod +x /etc/profile.d/java.sh

   sudo tee /opt/webserver/v6_tomcat/bin/setenv.sh<<-'EOF' 
       #JAVA_HOME=/usr/java/latest
       CATALINA_PID="$CATALINA_BASE/tomcat.pid"
       #CATALINA_OPTS="-server -Xms1024m -Xmx5120m -XX:PermSize=128m -XX:MaxPermSize=2048m -XX:NewSize=192m -XX:MaxNewSize=2048m -Dfile.encoding=UTF-8 -Dcom.sun.management.jmxremote  -Dcom.sun.management.jmxremote.port=1234  -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false"  
        CATALINA_OPTS="                  -Xms512m -Xmx2048m -XX:PermSize=128m -XX:MaxPermSize=256m -XX:NewSize=192m -XX:MaxNewSize=384m                -Dcom.sun.management.jmxremote  -Dcom.sun.management.jmxremote.port=8999  -Dcom.sun.management.jmxremote.ssl=false          -Dcom.sun.management.jmxremote.authenticate=false  "   
   EOF

   chmod +x  /opt/webserver/v6_tomcat/bin/setenv.sh

   ```````````````
   
=================== 
v6配置文件

	修改webservice配置文件
        find ./stage_*       |xargs -I {}  grep -iH  webservice {}    | cut -d ":" -f 1 |xargs -I {}  sh -c 'echo -e  =====file-name {} ======"\n";sed -i s/192.168.31.34/192.168.129.63/g {}'
 		find ./stage_* |xargs -I {}  grep -iH  webservice {}    | cut -d ":" -f 1 |xargs -I {}  sh -c 'echo -e  =====file-name {} ======"\n";sed  s/192.168.31.67/192.168.129.62/g {}' | grep "129.62\|file-name" 
        find ./stage_* |xargs -I {}  grep -iH  192.168.31.67 {} | cut -d ":" -f 1 |xargs -I {}  sh -c 'echo -e  =====file-name {} ======"\n";sed  s/192.168.31.67/192.168.129.62/g {}' | grep "129.62\|file-name"
	    
		find   ./perf_v6_mobile/ | grep -v "./perf_v6_mobile/$"    |xargs -I {}  grep -iH  webservice {}    | cut -d ":" -f 1 |xargs -I {}  sh -c 'echo -e  =====file-name {} ======"\n";sudo sed -i  s/192.168.31.34/192.168.129.63/g {}'
```````````````````````````````````````
        查询性能环境中缺少的配置文件
        { find  ./stage/   -type f  | xargs  -I {} sh -c 'a={}; echo   ${a/stage/xn} ' |xargs -I {} ls -l {} | grep "cannot access"; } 2>&1 |  sed -n  "s/.*\(\.\/xn.*\):.*/\1/p"
        查询性能环境中缺少的配置文件，从stage环境拷贝过去
        { find  ./stage/   -type f  | xargs  -I {} sh -c 'a={}; echo   ${a/stage/xn} ' |xargs -I {} ls -l {} | grep "cannot access"; } 2>&1 |  sed -n  "s/.*\(\.\/xn.*\):.*/\1/p"   | xargs -I {} sh -c 'a={}; cd stage;cp  --parent  ${a/.\/xn/.} ../xn '
 
		webservice查询：find   ./xn   -type f  |xargs -I {}  grep -iH  webService_url {}   
	    webservice修改：find   ./xn   -type f  |xargs -I {}  sed -i s/192.168.31.34/192.168.129.63/g {}   | grep -v '#'
	    tradews   查询：find   ./xn   -type f  |xargs -I {}  grep -iH  trade_url   {}
        
        redis     查询：find   -path ./xn*redis*    |  xargs -I {} grep -iH 'redis\.ip'  {}
        redis     修改：find   -path ./xn*redis*    |  xargs -I {}  sed -i s/192.168.31.67/192.168.129.62/g {}
		
		zookeeper 查询：find   -path ./xn*zook*    | xargs -I {} grep servers  {}
		                find   -path ./xn*zook*    | xargs -I {} sed -i s/192.168.31.34/192.168.129.63/g {}
		jdbc查询：	  
	          find ./xn   -type f  |xargs -I {}  grep -iH  jdbc\.url  {} | grep -v '#'
              find ./xn   -type f  |xargs -I {} sed -i s/rac-scan.xinxindai.com/192.168.129.75/g {}
              find ./xn   -type f  |xargs -I {} sed -i s/192.168.31.223/192.168.129.75/g {}			  
````````````````````````````````````	
	修改redis配置文件
        find ./stage_*/redis*     -type f | xargs sed -i  s/192.168.129.63/192.168.129.62/g
    
	检查grains配置文件
        salt *mobile0?    cmd.run "cat /etc/salt/grains|grep tomcat_app_dir|cut -d ':' -f 2-| xargs ls "
    
	nginxws配置文件
         salt perf_nginxws0? state.single file.managed  name='/etc/nginx/nginx.conf'         source='salt://files/nginx.conf.xxd' backup='minion'
         salt perf_nginxws0? state.single file.managed 'name=/etc/nginx/conf.d/tomcat.conf'  source='salt://files/tomcat.conf.xxd' backup='minion'
    
	rsync配置
         salt perf_nginx0?   state.single file.managed 'name=/etc/rsync.pass'  source='salt://configure/rsync.pass' backup='minion'
    
	nginx配置
	     ansible perf_ngi*   -m copy -a "src=/root/nginx-1.10.0.tar.gz dest=/root/"
	     scp root@192.168.31.22:/usr/local/nginx/conf/v6.xinxindai.com.crt          /etc/nginx/
         scp root@192.168.31.22:/usr/local/nginx/conf/v6.xinxindai_nopass.key       /etc/nginx/
		 
		 
	配置keepalived	 
     ``````````````
     ansible perf_nginxws0?  -m shell -a "yum install keepalived -y"
     
     salt    perf_nginxws0?  state.single file.managed name='/etc/keepalived/keepalived.conf'  source='salt://files/keepalived.conf' backup='minion'
     salt    perf_nginxws0?  file.list_backups  /etc/keepalived/keepalived.conf
     salt    perf_nginxws0?  state.single file.managed name='/root/nginx_pid.sh'  source='salt://files/nginx_pid.sh' backup='minion'
     ansible perf_nginxws01  -m shell -a "sed -i.bak3  s/192.168.31.34/192.168.129.63/g /etc/keepalived/keepalived.conf"
     ansible perf_nginxws02  -m shell -a "sed -i.bak3  -e s/state\ MASTER/state\ BACKUP/g  -e s/priority\ 100/priority\ 50/g  -e s/192.168.31.34/192.168.129.63/g /etc/keepalived/keepalived.conf"
     ````````` 
    配置zookeeper
	     ansible perf_salt       -m copy  -a "src=/root/zookeeper-3.4.8.tar.gz dest=/root/"
         find ./stage_*/zookeeper.p*|xargs -I {} sed -i.bak -e s/192.168.31.60/192.168.129.50/g -e s/192.168.31.61/192.168.129.51/g  -e  s/192.168.31.62/192.168.129.52/g   {} 
    
    安装zookeeper
         ansible perf_zookeep02  -m shell -a "cp  /root/xxd/zookeeper-3.4.8/conf/zoo_sample.cfg  /root/xxd/zookeeper-3.4.8/conf/zoo.cfg"
         ansible perf_zookeep02  -m shell -a "echo -e \"server.1=192.168.129.50:2888:3888\nserver.2=192.168.129.51:2888:3888\nserver.3=192.168.129.52:2888:3888\">>/root/xxd/zookeeper-3.4.8/conf/zoo.cfg"
         ansible perf_zookeep0?  -m shell -a "mkdir   /tmp/zookeeper/"
         ansible perf_zookeep01  -m shell -a "echo 1 >   /tmp/zookeeper/myid"
         echo -e "server.1=192.168.129.50:2888:3888\nserver.2=192.168.129.51:2888:3888\nserver.3=192.168.129.52:2888:3888"
         
         ansible perf_zookeep0?  -m shell -a "cd /root/xxd/zookeeper-3.4.8/bin/ &&./zkServer.sh restart"
         ansible perf_zookeep0?  -m shell -a "cd /root/xxd/zookeeper-3.4.8/bin/ &&./zkServer.sh status"
	
		 ansible perf_zookeep0?  -m shell -a "cd /root/xxd/zookeeper-3.4.8/bin/ &&./zkServer.sh start"
         ansible perf_zookeep0?  -m shell -a "cd /root/xxd/zookeeper-3.4.8/bin/ &&./zkServer.sh status"
         ansible perf_zookeep0?  -m shell -a "cd /root/xxd/zookeeper-3.4.8/bin/ &&./zkServer.sh stop"
		 
		 
     ```````````		 
     修改webservice配置文件
         find ./stage_* |xargs -I {}  grep -iH  webservice {} | cut -d ":" -f 1 |xargs -I {}  sh -c 'echo -e  =====file-name {} ======"\n";sed -i s/192.168.31.34/192.168.129.63/g {}'
		 
==========
salt安装

     ansible perf_zookeep0?  -m shell -a "echo 192.168.38.10 salt>>/etc/hosts"
``````
     ansible integration*   -m shell -a "sudo yum -y install https://repo.saltstack.com/yum/redhat/salt-repo-latest-1.el6.noarch.rpm"
     ansible perf_zookeep0?  -m shell -a " yum -y install salt-minion"      
``````
	 或ansible salt_perf*   -m shell -a "sudo yum -y install epel-release"
     
	 ansible salt_perf*      -m shell -a "yum --disablerepo=epel -y update  ca-certificates"
     ansible perf_zookeep0?  -m shell -a " yum update python  -y"
     ansible perf_salt       -m shell -a " yum -y install libselinux-python"
	 
     
	 
     
	 ansible perf_salt       -m shell -a  "service salt-master start; chkconfig salt-master on"
	 ansible perf_zookeep0?  -m shell -a  "service salt-minion start ;chkconfig  salt-minion on"
	 

	清除minion上的salt名称，重新到salt-master上认证
       ansible perf* -m shell -a ">  /etc/salt/minion_id"

	
	配置/etc/salt/master
     file_roots:
      base:
        - /srv/salt
==========
操作系统OS基础配置
配置host名称
     ansible perf_zookeep01  -m shell -a "sed -i.bak  s/HOSTNAME=.*/HOSTNAME=pf-zookeep01/g   /etc/sysconfig/network;hostname pf-zookeep01"

	 根据ansible配置文件批量修改hostname
     cat /etc/ansible/hosts| grep perf_ |awk '{print $1}'|xargs -I {} ansible {} -m shell -a "hostname {};sed -i.bak  s/HOSTNAME=.*/HOSTNAME={}/g   /etc/sysconfig/network ;hostname"
配置网络
     ansible perf*  -m shell -a "chkconfig iptables off"
     ansible perf_credit01 -m shell -a  "ip r add  172.16.0.0/255.255.0.0   via 192.168.129.253"
     ansible perf_credit01 -m shell -a  "ip r delete  default"
     ansible perf_credit01 -m shell -a  "ip r add  default via 192.168.129.254"
     ansible perf_credit01 -m shell -a  "ip r add  192.168.0.0/255.255.0.0   via 192.168.129.253"
    或  vi /root/ifup-local
    `````
    #!/bin/bash
	sudo tee /sbin/ifup-local<<-'EOF'  
    if [[ "$1" == "eth0" ]]
    then
         echo start configure $1    
         ip r add  172.16.0.0/255.255.0.0   via 192.168.129.253
         ip r delete  default
         ip r add  default via 192.168.129.254
         ip r add  192.168.0.0/255.255.0.0   via 192.168.129.253
    
    fi
	EOF
    chmod +x /sbin/ifup-local
	`````
    ansible perf_mobile01_tomcat  -m  script -a "/root/ifup-local"
	
安装zabbix agent
     ansible  perf*  -m  shell  -a  "rpm -Uvh http://repo.zabbix.com/zabbix/2.4/rhel/6/x86_64/zabbix-release-2.4-1.el6.noarch.rpm"
     ansible  perf*  -m  shell  -a  "yum -y install zabbix-agent"	 
	 ansible perf_*  -m copy     -a "src=/root/zabbix_agentd.conf            dest=/etc/zabbix/zabbix_agentd.conf  "
	 ansible perf_*       -m shell   -a " /etc/init.d/zabbix-agent restart "
	
============
安装redis
    ansible perf_redis0? -m copy -a "src=/root/redis-3.2.0.tar.gz   dest=/root/"
    ansible perf_redis0? -m shell -a "tar zxf /root/redis-3.2.0.tar.gz -C /root/" 
    cd  /root/redis-3.2.0/src  &&  yum -y groupinstall 'Development Tools' && make && make install

    sed -e "s/^daemonize no$/daemonize yes/" -e "s/^dir \.\//dir \/var\/lib\/redis\//" -e "s/^loglevel debug$/loglevel notice/" -e "s/^logfile stdout$/logfile \/var\/log\/redis.log/" redis.conf > /etc/redis/redis.conf    
=============




ansible perf_redis0? -m shell  -a "yum install  libselinux-python  -y"
ansible perf_redis01   -m shell -a "sed -i.bak  s/HOSTNAME=.*/HOSTNAME=pf-redis01/g   /etc/sysconfig/network;hostname pf-redis01"

ansible perf_nginxws0?  -m shell -a "sudo yum -y install epel-release"



ansible  perf_credit01  -m copy -a "src=/root/apache-tomcat-6.0.45.tar.gz   dest=/root/"
ansible perf*tomcat -m copy -a "src=/root/jdk-6u45-linux-x64-rpm.bin  dest=/root/"
ansible perf*tomcat -m shell  -a  "chmod +x /root/jdk-6u45-linux-x64-rpm.bin"


ansible perf*tomcat -m shell  -a   "yum -y remove java-1.7.0-openjdk.x86_64"
ansible perf*tomcat -m shell  -a   "yum -y remove java-1.6.0-openjdk.x86_64"

=====xxd grains检查====
检查tomcat部署目录是否合法
sudo  salt -L  "$minion_id"    cmd.run ' cat /etc/salt/grains|grep tomcat_app_dir|cut -d ':' -f 2-    | xargs ls  '

检查mount
sudo  salt -L  "$minion_id"    cmd.run "mount | grep 60.34"
=======



````nginx section`````````

sudo tee /etc/yum.repos.d/docker.repo <<-'EOF'
[dockerrepo]
name=Docker Repository
baseurl=https://yum.dockerproject.org/repo/main/centos/$releasever/
enabled=1
gpgcheck=1
gpgkey=https://yum.dockerproject.org/gpg
EOF

vi install_nginx.sh
sudo tee /etc/yum.repos.d/nginx.repo<<-'EOF'
[nginx]
name=nginx repo
baseurl=http://nginx.org/packages/centos/6/$basearch/
gpgcheck=0
enabled=1
EOF
ansible perf_ngi*   -m  script -a "/root/install_nginx.sh"
ansible perf_ngi*  -m shell -a "cat /etc/yum.repos.d/nginx.repo"
ansible perf_ngi*  -m shell -a "yum -y install nginx"
ansible perf_ngi*  -m shell -a "/etc/init.d/nginx start"
ansible perf_ngi*  -m shell -a "nginx -v"


```zabbix section````````
{192.168.31.196:system.run[/opt/dell/srvadmin/bin/omreport storage pdisk controller=0 ].regexp(^Status.*Ok,#1)}=0
 cat   2015-10-15.csv | grep -v '^$' |awk '{ for (i=1;i<=NF;i++) {   print $i NR-1  }  }'
``````````
virsh list --all| grep runn   | awk '{print $2}' |xargs  -I '{}' sh -c "echo -n {} ' ' ;sudo virsh domiflist {}|grep vnet|awk '{printf \"%s \", \$5  }';echo "
nmap -sP 192.168.31.0/24   > network31.txt
grep -i 52:54:00:3d:a1:03  network31.txt -B 2 | grep -v Host
````````````````

virsh list --all| grep runn                   | awk '{print $2}' |xargs  -I '{}' sh -c "echo {} ;sudo virsh domiflist '{}'"

docker build --rm -t local/centos7-reviewboard   .
docker commit --change='CMD ["/root/start.sh"]'   --change='ENTRYPOINT ["/tini", "--"]'  -c "EXPOSE 8080"  pensive_austin    xxd-tomcat:final
sudo salt 'test_v6_redis01' cmd.run "netstat -antup| grep redis| awk '{print \$5}' | awk -F: '{print \$1}'" | grep 192|xargs -I {} grep  -B 1 {} ./office.ip.list

http://192.168.38.119/cdh5.5.0-parcels/
http://192.168.38.119/centos6-cm5.5.0

salt-ssh -i    cloudera-agent3    state.low '{ {% set my_path = salt['grains.get']('id') %} ,  state: cmd ,fun: run ,name: "unzip -o /root/v6_webservice.war  -d  /tmp/root{{ my_path }}" }'

```pv section````
svn list  http://192.168.38.230/YXITD/saltstack/trunk/wujunrong/    --username wujunrong| grep  ansible |xargs -I {} svn export  http://192.168.38.230/YXITD/saltstack/trunk/wujunrong/{} --force  /etc/ansible/hosts
ansible test_nginx    -m fetch  -a "src=/var/log/nginx/bigdata_pv.log     dest=/opt/logs/share/{{ inventory_hostname }}.bigdata_pv.log  flat=yes"
```````````````````

del "\"sys_cofing_RISK_CALL_SWITCH\""

redis安装在192.168.32.251上
huangchao(黄超（高级系统工程师）) 11-30 17:32:50
硬盘给50G就可以了

ansible  fix-env   -m shell -a "cd  /tmp/v6/install_packet/&& zip ./conf_file.zip ./redis.properties"
=======================
v6test

nginx:
192.168.38.182:/var/ftp/pub/v6_front/image   /usr/local/nginx/html/static/image
192.168.38.182:/var/ftp/pub/v6_admin/image   /usr/local/nginx/html/static/admin/image 
192.168.38.182:/var/ftp/pub/download         /usr/local/nginx/html/static/download 

front:
192.168.38.182:/var/ftp/pub/v6_front/image   /opt/webserver/v6_tomcat/webapps/ROOT/static/image 
192.168.38.182:/var/ftp/pub/v6_admin/image   /opt/webserver/v6_tomcat/webapps/ROOT/static/admin/image 

mobile



192.168.38.182:/var/ftp/pub/v6_front/image   /opt/webserver/v6_tomcat/webapps/v5_mobile/static/image 
192.168.38.182:/var/ftp/pub/v6_admin/image   /opt/webserver/v6_tomcat/webapps/v5_mobile/static/admin/image 

webapp
192.168.38.182:/var/ftp/pub/v6_front/image   /opt/webserver/v6_tomcat/webapps/m/static/image
=============================
v6stage
nginx
192.168.31.250:/volume1/v6/v6_front/image    /usr/local/nginx/html/static/image type nfs (rw,vers=4,addr=192.168.31.250,clientaddr=192.168.31.24)
192.168.31.250:/volume1/v6/v6_admin/image    /usr/local/nginx/html/static/admin/image type nfs (rw,vers=4,addr=192.168.31.250,clientaddr=192.168.31.24)
192.168.31.250:/volume1/v6/download          /usr/local/nginx/html/static/download type nfs (rw,vers=4,addr=192.168.31.250,clientaddr=192.168.31.24)

webapp
192.168.31.250:/volume1/v6/v6_front/image    /opt/webserver/v6_tomcat/webapps/m/static/image

===================

unzip -o /tmp/v6/install_packet/conf_file.zip -d /opt/webserver/v6_tomcat/webapps/xxdai_sys_admin/WEB-INF/classes/

sudo salt -N 'test_v6tomcat' cmd.run "find /opt/webserver/ -type d  -print0 |  grep -EzZ  'classes/com$' |sed 's/WEB-INF\/classes\/com//g';echo"
sudo salt -N 'stage_v6tomcat'  cmd.run "find /opt/webserver/ -type d  -print0 |  grep -EzZ  'classes/com$' |sed 's/WEB-INF\/classes\/com//g';echo;salt-call --local  grains.item  tomcat_app_dir | grep opt | xargs -I {}  sh -c 'echo {};[ -d {} ] && echo found  || echo not found  '  "


test_v6_seo:
    /opt/webserver/v6_tomcat/webapps/ROOT/
test_v6_webapp_front01:
    /opt/webserver/v6_tomcat/webapps/m/
test_v6_tomcat_admin01:
    /opt/webserver/v6_tomcat/webapps/v6_admin/
test_v6_tomcat_batch01:
    /opt/webserver/v6_tomcat/webapps/xxdai_batch/
test_v6_tomcat_mobile02:
    /opt/webserver/v6_tomcat/webapps/v5_mobile/
test_v6_tomcat_front02:
    /opt/webserver/v6_tomcat/webapps/ROOT/
test_v6_tomcat_admin02:
    /opt/webserver/v6_tomcat/webapps/v6_admin/
test_v6_tomcat_batch02:
    /opt/webserver/v6_tomcat/webapps/xxdai_batch/
test_v6_tomcat_front01:
    /opt/webserver/v6_tomcat/webapps/ROOT/
test_v6_tomcat_tradew01:
    /opt/webserver/v6_tomcat/webapps/v6_tradews/
test_v6_tomcat_mobile01:
    /opt/webserver/v6_tomcat/webapps/v5_mobile/
test_v6_tomcat_webservice01:
    /opt/webserver/v6_tomcat/webapps/v6_webservice/
test_v6_tomcat_tradew02:
    /opt/webserver/v6_tomcat/webapps/v6_tradews/
test_v6_tomcat_webservice02:
    /opt/webserver/v6_tomcat/webapps/v6_webservice/

======log section==========
tar  -zcvf /tmp/wutest.tar.gz   `find . -type f -newerct "2016-03-07  15:00:00"   ! -newerct "2016-03-07 17:00:00"   -regex ".*mobile.*\|.*webser.*" `
find . -type f -newerct "2016-02-07  00:00:00"   ! -newerct "2016-03-08 00:00:00"   | xargs -I {}  sh -c 'echo == {} ==;zcat {} | grep -anE -C 20 "AccountRechargeServiceImpl...updateAccountRecharge...BankCode=" ' >/tmp/webservice_yangzhe_0207-0307.txt

ansible stage_tomcat_webservice    -m fetch  -a "src=/opt/webserver/v6_tomcat/logs/catalina.out   dest=/tmp/{{ inventory_hostname  }}.out  flat=yes"
zip catalina.zip *.out
ansible stage_tomcat_webservice    -m fetch  -a "src=/opt/webserver/v6_tomcat/logs/localhost.2016-06-24.log   dest=/tmp/{{ inventory_hostname  }}.log  flat=yes
============

sudo  salt 'ct-production-tomcat-partener02.xinxindai.com' cp.push '/opt/webserver/tomcat/webapps/v6_partener/WEB-INF/classes/discuz.properties'
sudo  find /var/cache/salt/master/minions/    -name discuz.properties   -exec cp {} /srv/salt/wujunrong/discuz.properties   \;
sudo  salt     'ct-production-tomcat-partener01.xinxindai.com'     file.manage_file /opt/webserver/tomcat/webapps/v6_partener/WEB-INF/classes/discuz.properties    '' '{}' salt://wujunrong/discuz.properties     '{hash_type: 'md5', 'hsum': <md5sum>}' root root '644' base 'minion'

堡垒：super/YXauth!@#xxd001

===deploy section========
diff -r /opt/ci/rsync/v6_static_rsync/    /opt/ci/workspace/dev_v6.4.4_20160308/v6_front/trunk/target/v6_front/static/
find   /opt/ci/workspace/dev_v6.4.4_20160308/  -name pom.xml -exec sh -c 'path_dir=`dirname {}`; cd $path_dir;mvn clean package;' \;
````
rm -fr /opt/ci/rsync/v6_static_rsync/*
cp -r  /opt/ci/workspace/dev_v6.4.4_20160308/v6_front/trunk/target/v6_front/static/*  /opt/ci/rsync/v6_static_rsync/
````
========elasticsearch section=====
31.160和31.162 上有fluem服务，在lib目录 /opt/cloudera/parcels/CDH-5.5.0-1.cdh5.5.0.p0.8/lib/flume-ng/lib中增加 elasticsearch-1.7.1.jar 文件

salt 'stage_v6_admin01' state.single   file.recurse  source='salt://wujunrong/20160321config/abc'  name='/opt/webserver/v6_tomcat/webapps/xxdai_sys_admin/image/data/xheditor_Upload'




touch /home/wujunrong/tmp/error.txt;find  ./  -type d  -path ./v6_batch/trunk/batch-schedule -prune -o  -name pom.xml   -print | grep -v "v6_batch/trunk/pom.xml" |  xargs -I {}  sh -c 'path_dir=`dirname {}`&& cd $path_dir && mvn clean package ; return_val=$?  | tee ./output.txt; (if [ "$return_val" -ne 0 ];then ( cat ./output.txt  >>/home/wujunrong/tmp/error.txt)  ;else  cp  ./target/*.war   /home/wujunrong/tmp/;fi)   '

主机名规范：环境-(业务)-运行服务-ip.地点
           test-v6_front01-tomcat-192.168.38.1.yh
           base-svn_master-192.168.1.1.yh
           stage-hypervisor_kvm01-192.168.1.2.yh
		   


==============生产================
hyper-pingtai.xinxindai.com
         dns                                            192.168.110.101    52:54:00:8B:46:49
         ks_cobbler                                     192.168.110.104    52:54:00:CA:72:39  
         monitor                                        192.168.110.60     52:54:00:85:96:A2
         salt                                           192.168.110.102    52:54:00:49:31:C7
         discuz001                                      192.168.10.14
         v5_sc_mysql                                    192.168.110.106    52:54:00:CA:FD:8C
         yw_redis01                                     192.168.110.107    52:54:00:00:A6:C0
         log                                            192.168.110.105    52:54:00:27:67:FF
         v6_front04                                     192.168.110.78     52:54:00:27:61:F1
         saltweb.xinxindai.com                          192.168.110.108    52:54:00:A8:6C:5D
         ansible
         xinxindai-rtx


hyper-v6_pro03.xinxindai.com
      v6_nginx03                                     192.168.110.24     52:54:00:7D:0C:00
      v6_front03                                     192.168.110.28     52:54:00:2D:CE:C8
      v6_webservice03                                192.168.110.42     52:54:00:E2:EE:04
      v6_tradew03                                    192.168.110.45     52:54:00:DA:57:34
      v6_mobile02                                    192.168.110.71     52:54:00:06:60:0D
      v6_zookeeper03                                 192.168.110.50     52:54:00:77:2D:BA
      v6_webapp_front02                              192.168.110.73     52:54:00:F2:0E:48
      ct-production-tomcat-partener02.xinxindai.com  192.168.110.80     52:54:00:39:31:56
      sftp_slave_192.168.110.91                      192.168.110.91     52:54:00:7E:BF:44

hyper-v6_pro01.xinxindai.com
      v6_lvs01                                       192.168.110.20     52:54:00:13:72:E3
                                                     192.168.110.25     52:54:00:13:72:E3
      v6_nginx01                                     192.168.110.22     52:54:00:9A:67:E7
      v6_front01                                     192.168.110.26     52:54:00:BC:0D:5E
      v6_admin01                                     192.168.110.29     52:54:00:A2:60:6A
      v6_nginxws01                                   192.168.110.31     52:54:00:C6:A2:55
                                                     192.168.110.33     52:54:00:C6:A2:55
      v6_webservice01                                192.168.110.40     52:54:00:F2:DE:17
      v6_tradew01                                    192.168.110.43     52:54:00:5A:42:9E
      v6_batch01                                     192.168.110.46     52:54:00:14:8C:F8
      v6_redis01                                     192.168.110.51     52:54:00:A8:89:4B
                                                     192.168.110.53     52:54:00:A8:89:4B
      v6_zookeeper01                                 192.168.110.48     52:54:00:EF:9F:33
      v6_seo01                                       192.168.110.76     52:54:00:8A:DB:1F
      v6_credit_app01                                192.168.110.81     52:54:00:9F:D0:11

hyper-v6_pro02.xinxindai.com
      v6_lvs02                                       192.168.110.21     52:54:00:8D:AB:67
      v6_nginx02                                     192.168.110.23     52:54:00:31:5D:D4
      v6_front02                                     192.168.110.27     52:54:00:10:68:1D
      v6_admin02                                     192.168.110.30     52:54:00:1C:DA:41
      v6_nginxws02                                   192.168.110.32     52:54:00:A0:15:A2
      v6_webservice02                                192.168.110.41     52:54:00:6D:D2:5B
      v6_tradew02                                    192.168.110.44     52:54:00:A9:7F:C7
      v6_batch02                                     192.168.110.47     52:54:00:B9:25:A0
      v6_redis02                                     192.168.110.52     52:54:00:41:CB:0E
      v6_mobile01                                    192.168.110.70     52:54:00:7C:80:42
      v6_zookeeper02                                 192.168.110.49     52:54:00:B2:1F:36
      v6_webapp_front01                              192.168.110.72     52:54:00:38:5D:B8
      v6_seo02                                       192.168.110.77     52:54:00:E9:C7:C4
      ct-production-tomcat-partener01.xinxindai.com  192.168.110.79     52:54:00:C8:27:86
      v6_credit_app02                                192.168.110.82     52:54:00:35:DF:42
      sftp_master_192.168.110.90                     192.168.110.90     52:54:00:7A:76:BB


hyper-host2
       nginx02 192.168.50.62 52:54:00:49:4F:87
       auth02  192.168.50.64 52:54:00:66:31:35
       app2    192.168.50.71 52:54:00:A2:2D:B7
       fk002   192.168.50.56 52:54:00:9C:0E:3A

hyper-host1
      nginx01  192.168.50.60 52:54:00:93:B9:83
               192.168.50.61 52:54:00:93:B9:83
      auth01   192.168.50.63 52:54:00:08:0E:E3    key认证
      app1     192.168.50.70 52:54:00:25:A5:A0    OA
      fk001    192.168.50.55 52:54:00:37:B5:47
      xinxindai-rtx-20160620
	  
	  
hyper-cloudera-pro
      cloudera-appserver                                                     52:54:00:9F:27:49
      cloudera-dashboard                                  192.168.32.21      52:54:00:10:05:F2
	  cloudera-flume01                                    192.168.32.19      52:54:00:27:FB:06
      cloudera-flume02                                    192.168.32.20
      cloudera-redis01                                    192.168.32.50      52:54:00:3B:C2:3E
      cloudera-redis02                                    192.168.32.51      52:54:00:38:66:18
      ct-production-hadoop-dashboard_mysql.xinxindai.com  192.168.32.252     52:54:00:C7:54:96
      cloudera-ace-ws                                     192.168.32.23      52:54:00:DC:BD:B9
==============办公室==============

v6_stage3:hyper-YH-Virtualization-KVM08-192.168.31.17.xinxindai.com
        jenkins                                                  192.168.31.81      52:54:00:0B:72:59
        stage_oa.xinxindai.com                                   192.168.31.40      52:54:00:A0:CE:68
        stage_oa2.xinxindai.com                                  192.168.31.41      52:54:00:DD:63:58
        stage_oa3.xinxindai.com
        stage_v6_admin03                                         192.168.31.31      52:54:00:A7:91:48
        stage_v6_front03                                         192.168.31.28      52:54:00:E4:49:1A
        stage_v6_mobile01.xinxindai.com                          192.168.31.70      52:54:00:8F:19:66
        stage_v6_nginx03                                         192.168.31.24      52:54:00:BE:B6:0C
        stage_v6_redis02                                         192.168.31.66      52:54:00:4E:1E:F2
        stage_v6_seo002                                          192.168.31.88      52:54:00:02:FC:E4
        stage_v6_tradew03                                        192.168.31.56      52:54:00:B5:F2:EC
        stage_v6_webapp02                                        192.168.31.73      52:54:00:BC:45:91
        stage_v6_webservice03                                    192.168.31.52      52:54:00:0E:2D:56
        stage_v6_zookeeper03                                     192.168.31.62      52:54:00:EB:7C:BC
v6_stage1:hyper-YH-Virtualization-KVM06-192.168.31.15.xinxindai.com
        ct-stage-tomcat-partener01.xinxindai.com                 192.168.31.90      52:54:00:AC:3F:87
        stage_fk001                                              192.168.31.85      52:54:00:E3:B4:7E
        stage_fk_nginx01                                         192.168.31.82      52:54:00:E9:3F:F5
                                                                 192.168.31.83      52:54:00:E9:3F:F5
        stage_v6_admin01                                         192.168.31.29      52:54:00:EC:87:DF
        stage_v6_batch02                                         192.168.31.57      52:54:00:34:FD:30
        stage_v6_front01                                         192.168.31.26      52:54:00:2F:0A:E3
        stage_v6_lvs01                                           192.168.31.20      52:54:00:3E:28:62
                                                                 192.168.31.25      52:54:00:3E:28:62
        stage_v6_nginx01                                         192.168.31.22      52:54:00:41:9C:3B
        stage_v6_nginxws01                                       192.168.31.32      52:54:00:56:D5:EE
                                                                 192.168.31.34      52:54:00:56:D5:EE
        stage_v6_tradew01                                        192.168.31.54      52:54:00:8D:9C:9D
        stage_v6_webservice01                                    192.168.31.50      52:54:00:A9:DF:AF
        stage_v6_zookeeper01                                     192.168.31.60      52:54:00:89:72:F0
        stage-v6_credit_app01-tomcat-192.168.31.89.yh            192.168.31.89      52:54:00:12:EB:1E
		
v6_stage2:hyper-YH-Virtualization-KVM07-192.168.31.16.xinxindai.com
        ct-stage-tomcat-partener02.xinxindai.com                 192.168.31.91      52:54:00:77:6B:12
        stage_fk002                                              192.168.31.86      52:54:00:97:A8:A8
        stage_fk_nginx02                                         192.168.31.84      52:54:00:72:12:6E
        stage_v6_admin02                                         192.168.31.30      52:54:00:65:50:95
        stage_v6_batch02                                         192.168.31.58      52:54:00:11:01:89
        stage_v6_front02                                         192.168.31.27      52:54:00:11:FB:BC
        stage_v6_lvs02                                           192.168.31.21      52:54:00:95:20:E4
        stage_v6_mobile02                                        192.168.31.71      52:54:00:07:B0:8A
        stage_v6_nginx02                                         192.168.31.23      52:54:00:E6:77:0F
        stage_v6_nginxws02                                       192.168.31.33      52:54:00:8A:C9:A7
        stage_v6_redis01                                         192.168.31.65      52:54:00:E3:AC:88
                                                                 192.168.31.67      52:54:00:E3:AC:88
        stage_v6_seo001                                          192.168.31.87      52:54:00:B8:3C:E9
        stage_v6_tradew02                                        192.168.31.55      52:54:00:62:18:78
        stage_v6_webapp01                                        192.168.31.72      52:54:00:FF:E9:99
        stage_v6_webservice02                                    192.168.31.51      52:54:00:BD:6F:02
        stage_v6_zookeeper02                                     192.168.31.61      52:54:00:77:79:32
hypervisor_v6_test2:hyper-YH-Virtualization-KVM04-192.168.38.200.xinxindai.com
        test_fkoracle                                            192.168.38.156     52:54:00:08:9C:96
        oracle_test                                              192.168.38.207     52:54:00:97:9D:E8
        ct-test-tomcat-partener01.xinxindai.com                  192.168.38.183     52:54:00:33:B6:2A
        dev_zookeeper                                            192.168.38.163     52:54:00:77:CD:29
        dev_zookeeper02                                          192.168.38.164     52:54:00:C8:70:1E
        dev_zookeeper03                                          192.168.38.165     52:54:00:E2:36:CC
        lvs01                                                    192.168.38.170     52:54:00:A9:0C:8B
                                                                 192.168.38.175     52:54:00:A9:0C:8B
        nginx01                                                  192.168.38.172     52:54:00:BC:A9:74
        redis01                                                  192.168.38.176     52:54:00:66:2B:5B
                                                                 192.168.38.178     52:54:00:66:2B:5B
        test_fk001                                               192.168.38.155     52:54:00:F9:FC:9C
        test_fk002                                               192.168.38.157     52:54:00:90:8C:C2
        test_fk_nginx                                            192.168.38.154     52:54:00:BE:56:9F
        test_v6_tomcat_mobile01                                  192.168.38.158     52:54:00:26:57:12
        tomcat_admin02                                           192.168.38.141     52:54:00:F2:CA:D6
        tomcat_batch02                                           192.168.38.147     52:54:00:5F:C9:A6
        tomcat_tran02                                            192.168.38.153     52:54:00:8E:CC:8C
        tomcat_webservice02                                      192.168.38.143     52:54:00:1D:EF:BB
        v6tomcat1                                                192.168.38.160     192.168.38.161     52:54:00:25:62:AF
        zookeeper01                                              192.168.38.180     52:54:00:67:00:4C
        test-v6_credit_app01-192.168.38.160.yh
        testmxli

hypervisor_v6_test1:hyper-YH-Virtualization-KVM03-192.168.38.190.xinxindai.com
        svnbackup                                                192.168.38.229     52:54:00:29:54:D7
        oracletech                                               192.168.38.219     52:54:00:12:B4:BA
        oracle01                                                 192.168.38.107     52:54:00:BB:FE:1F
        v6nfs                                                    192.168.38.182     52:54:00:72:C4:0E
        ct-test-tomcat-partener02.xinxindai.com                  192.168.38.184     52:54:00:86:6A:E8
        donglian                                                 192.168.38.218     52:54:00:C4:EF:A1
        lvs02                                                    192.168.38.171     52:54:00:C8:D7:0B
        monitor                                                  192.168.38.169     52:54:00:1F:EF:55
        nginx02                                                  192.168.38.173     52:54:00:20:B0:2A
        nginx_service01                                          192.168.38.148     52:54:00:EB:C5:1C
                                                                 192.168.38.152     52:54:00:EB:C5:1C
        nginx_service02                                          192.168.38.149     52:54:00:F6:AE:5E
        redis02                                                  192.168.38.177     52:54:00:C4:54:3F
        rewrite                                                  192.168.38.151     52:54:00:C6:50:3A
        test_v6_tomcat_mobile02                                  192.168.38.159     52:54:00:8B:AD:12
        test_v6_webapp_front01                                   192.168.38.206     52:54:00:BA:E0:C1
        test_v6_webapp_webservice01                              192.168.38.208     52:54:00:52:A3:9E
        tomcat_admin01                                           192.168.38.140     52:54:00:61:73:98
        tomcat_batch01                                           192.168.38.146     52:54:00:3B:AC:C3
        tomcat_tran01                                            192.168.38.144     52:54:00:F0:2E:83
        tomcat_webservice01                                      192.168.38.142     52:54:00:A0:F0:29
        v6tomcat2                                                192.168.38.162     52:54:00:47:BC:56
        zookeeper02                                              192.168.38.181     52:54:00:D4:16:A7
        saltstack                                                192.168.38.10      52:54:00:BB:32:1F

cloudera_test:ct-production-hadoop-dashboard_mysql.xinxindai.com
        cloudera-ace-ws
        hyper-hadoop-test
        cloudera_mysql                                           192.168.31.150     52:54:00:0D:11:2C
        fileshare-v6-logserver                                   192.168.31.155     52:54:00:8F:8C:2D
        h-hadoop-data03                                          192.168.31.164     52:54:00:77:F1:E3
        h_hadoop_dashboard                                       192.168.31.168     52:54:00:7C:86:61
        h_hadoop_data01                                          192.168.31.162     52:54:00:B9:81:1C
        h_hadoop_data02                                          192.168.31.163     52:54:00:5C:7A:35
        h_hadoop_master                                          192.168.31.160     52:54:00:80:C4:07
        h_hadoop_slave                                           192.168.31.161     52:54:00:DD:85:AC
平台_backup:hyper-YH-Virtualization-KVM02-192.168.38.100.xinxindai.com	
        git                                                      192.168.38.12      52:54:00:C3:4A:E8
        jumpserver                                               192.168.38.121     52:54:00:0F:D2:3F
        logstash                                                 192.168.38.11      52:54:00:AF:D3:C5
        luo_test                                                 192.168.38.205     52:54:00:84:8D:D9
        mysql_testdb                                             192.168.38.235     52:54:00:4E:29:EB
        openldap-master                                          192.168.38.120     52:54:00:6F:F8:EA
        saltweb                                                  192.168.38.122     52:54:00:FE:D3:6D
        v4_test001                                               192.168.38.232     52:54:00:A9:ED:5F
        v5_sc_mysql                                              192.168.38.111     52:54:00:96:E8:0C
        v5_stage001                                              192.168.38.145     52:54:00:71:0F:F9
                                                                 192.168.38.236     52:54:00:71:0F:F9
        redmine                                                  192.168.38.239     52:54:00:36:6B:DB
        YH-base-ansible01-192.168.38.13.xinxindai.com            192.168.38.13      52:54:00:2C:69:A1		
		
v6_fix:YH-Virtualization-KVM05-192.168.31.200.xinxindai.com
        test_lvs001                                              192.168.31.101     52:54:00:2A:9D:D6
        test_lvs002                                              192.168.31.100     52:54:00:AF:61:7A
                                                                 192.168.31.102     52:54:00:AF:61:7A
        v6mon_front002                                           192.168.31.107     52:54:00:AB:66:72
        v6mon_redies001                                          192.168.31.127     52:54:00:0C:44:51
        v6mon_redies002                                          192.168.31.126     52:54:00:2F:32:EC
                                                                 192.168.31.128     52:54:00:2F:32:EC
        v6mon_redies003                                          192.168.31.129     52:54:00:F2:7C:3C
        v6mon_zookeeper001                                       192.168.31.130     52:54:00:E2:B5:96
        test_nginx001                                            192.168.31.103     52:54:00:1A:5A:BB
        test_nginx002                                            192.168.31.104     52:54:00:BD:7D:A8
        v6_admin001                                              192.168.31.205     52:54:00:91:0E:04
        v6_batch001                                              192.168.31.213     52:54:00:35:85:8E
        v6_front001                                              192.168.31.203     52:54:00:7C:19:91
        v6_redies001                                             192.168.31.215     52:54:00:95:2D:35
        v6_trader001                                             192.168.31.211     52:54:00:88:20:B4
        v6_webservice001                                         192.168.31.209     52:54:00:6C:5B:1F
        v6_zookeeper001                                          192.168.31.217     52:54:00:76:D5:9A
        v6mon_admin001                                           192.168.31.109     52:54:00:B5:22:A8
        v6mon_batch001                                           192.168.31.124     52:54:00:84:95:2C
        v6mon_front001                                           192.168.31.106     52:54:00:32:75:37
        v6mon_mobile001                                          192.168.31.112     52:54:00:F9:DB:1F
        v6mon_trader001                                          192.168.31.121     52:54:00:91:DF:94
        v6mon_webapp001                                          192.168.31.115     52:54:00:B0:EE:09
        v6mon_webservice001                                      192.168.31.118     52:54:00:A7:CA:6F
        CT-YH-v6test2-credit_app01-192.168.31.206-xinxindai.com  192.168.31.206     52:54:00:D6:14:6B

平台:hyper-YH-Virtualization-KVM01-192.168.38.250.xinxindai.com
        windows_kaoqin                                            192.168.38.237  52:54:00:8D:A5:DA
        windows2008                                               192.168.38.238  52:54:00:5A:DB:DA
        maven                                                     192.168.38.240  52:54:00:E8:BC:49
        svn                                                       192.168.38.230  52:54:00:01:38:C0
        discuz001                                                 192.168.38.249  52:54:00:98:06:15
        dns                                                       192.168.38.118  52:54:00:35:A0:2C
        kaoqin                                                    192.168.38.127  52:54:00:80:B1:C7
        file001_sms   短信                                        192.168.38.209  52:54:00:AB:2D:7B
        cobbler                                                   192.168.38.119  52:54:00:81:15:ED

		
 find ./grains.stage_* | xargs -I {} sed  -i  "s/ci\/files\/stage_v6_admin/wujunrong\/xxd_configure\/stage\/v6\/admin/g"   {}
 find ./grains.stage_* | xargs -I {} sed  -i  "s/ci\/files\/stage_v6_batch/wujunrong\/xxd_configure\/stage\/v6\/batch/g"   {}        
 find ./grains.stage_* | xargs -I {} sed  -i  "s/ci\/files\/stage_v6_credit_app/wujunrong\/xxd_configure\/stage\/v6\/credit/g"   {}  
 find ./grains.stage_* | xargs -I {} sed  -i  "s/ci\/files\/stage_v6_front/wujunrong\/xxd_configure\/stage\/v6\/front/g"   {}        
 find ./grains.stage_* | xargs -I {} sed  -i  "s/ci\/files\/stage_v6_mobile/wujunrong\/xxd_configure\/stage\/v6\/mobile/g"   {}
 find ./grains.stage_* | xargs -I {} sed  -i  "s/ci\/files\/stage_v6_seo/wujunrong\/xxd_configure\/stage\/v6\/seo/g"   {}
 find ./grains.stage_* | xargs -I {} sed  -i  "s/ci\/files\/stage_v6_tradew/wujunrong\/xxd_configure\/stage\/v6\/tradews/g"   {}
 find ./grains.stage_* | xargs -I {} sed  -i  "s/ci\/files\/stage_v6_webapp/wujunrong\/xxd_configure\/stage\/v6\/webapp/g"   {}
 find ./grains.stage_* | xargs -I {} sed  -i  "s/ci\/files\/stage_v6_webservice/wujunrong\/xxd_configure\/stage\/v6\/webservice/g"   {}
 
 
 find ./grains.fix_* | xargs -I {} sed  -i  "s/ci\/files\/data_v6_admin/wujunrong\/xxd_configure\/fix\/v6\/admin/g"   {}
 find ./grains.fix_* | xargs -I {} sed  -i  "s/ci\/files\/data_v6_batch/wujunrong\/xxd_configure\/fix\/v6\/batch/g"   {}        
 find ./grains.fix_* | xargs -I {} sed  -i  "s/ci\/files\/data_v6_credit_app/wujunrong\/xxd_configure\/fix\/v6\/credit/g"   {}  
 find ./grains.fix_* | xargs -I {} sed  -i  "s/ci\/files\/data_v6_front/wujunrong\/xxd_configure\/fix\/v6\/front/g"   {}        
 find ./grains.fix_* | xargs -I {} sed  -i  "s/ci\/files\/data_v6_mobile/wujunrong\/xxd_configure\/fix\/v6\/mobile/g"   {}
 find ./grains.fix_* | xargs -I {} sed  -i  "s/ci\/files\/data_v6_seo/wujunrong\/xxd_configure\/fix\/v6\/seo/g"   {}
 find ./grains.fix_* | xargs -I {} sed  -i  "s/ci\/files\/data_v6_tradew/wujunrong\/xxd_configure\/fix\/v6\/tradews/g"   {}
 find ./grains.fix_* | xargs -I {} sed  -i  "s/ci\/files\/data_v6_webapp/wujunrong\/xxd_configure\/fix\/v6\/webapp/g"   {}
 find ./grains.fix_* | xargs -I {} sed  -i  "s/ci\/files\/data_v6_webservice/wujunrong\/xxd_configure\/fix\/v6\/webservice/g"   {}
 
 find ./grains.temp_* | xargs -I {} sed  -i  "s/ci\/files\/temp_v6_admin/wujunrong\/xxd_configure\/test2\/v6\/admin/g"   {}
 find ./grains.temp_* | xargs -I {} sed  -i  "s/ci\/files\/temp_v6_batch/wujunrong\/xxd_configure\/test2\/v6\/batch/g"   {}        
 find ./grains.temp_* | xargs -I {} sed  -i  "s/ci\/files\/temp_v6_credit_app/wujunrong\/xxd_configure\/test2\/v6\/credit/g"   {}  
 find ./grains.temp_* | xargs -I {} sed  -i  "s/ci\/files\/temp_v6_front/wujunrong\/xxd_configure\/test2\/v6\/front/g"   {}        
 find ./grains.temp_* | xargs -I {} sed  -i  "s/ci\/files\/temp_v6_mobile/wujunrong\/xxd_configure\/test2\/v6\/mobile/g"   {}
 find ./grains.temp_* | xargs -I {} sed  -i  "s/ci\/files\/temp_v6_seo/wujunrong\/xxd_configure\/test2\/v6\/seo/g"   {}
 find ./grains.temp_* | xargs -I {} sed  -i  "s/ci\/files\/temp_v6_tradew/wujunrong\/xxd_configure\/test2\/v6\/tradews/g"   {}
 find ./grains.temp_* | xargs -I {} sed  -i  "s/ci\/files\/temp_v6_webapp/wujunrong\/xxd_configure\/test2\/v6\/webapp/g"   {}
 find ./grains.temp_* | xargs -I {} sed  -i  "s/ci\/files\/temp_v6_webservice/wujunrong\/xxd_configure\/test2\/v6\/webservice/g"   {}
 
 
 find ./grains.perf_* | xargs -I {} sed  -i  "s/ci\/files\/temp_v6_admin/wujunrong\/xxd_configure\/test2\/v6\/admin/g"   {}
 find ./grains.perf_* | xargs -I {} sed  -i  "s/ci\/files\/temp_v6_batch/wujunrong\/xxd_configure\/test2\/v6\/batch/g"   {}        
 find ./grains.perf_* | xargs -I {} sed  -i  "s/ci\/files\/temp_v6_credit_app/wujunrong\/xxd_configure\/test2\/v6\/credit/g"   {}  
 find ./grains.perf_* | xargs -I {} sed  -i  "s/ci\/files\/temp_v6_front/wujunrong\/xxd_configure\/test2\/v6\/front/g"   {}        
 find ./grains.perf_* | xargs -I {} sed  -i  "s/ci\/files\/temp_v6_mobile/wujunrong\/xxd_configure\/test2\/v6\/mobile/g"   {}
 find ./grains.perf_* | xargs -I {} sed  -i  "s/ci\/files\/temp_v6_seo/wujunrong\/xxd_configure\/test2\/v6\/seo/g"   {}
 find ./grains.perf_* | xargs -I {} sed  -i  "s/ci\/files\/temp_v6_tradew/wujunrong\/xxd_configure\/test2\/v6\/tradews/g"   {}
 find ./grains.perf_* | xargs -I {} sed  -i  "s/ci\/files\/temp_v6_webapp/wujunrong\/xxd_configure\/test2\/v6\/webapp/g"   {}
 find ./grains.perf_* | xargs -I {} sed  -i  "s/ci\/files\/temp_v6_webservice/wujunrong\/xxd_configure\/test2\/v6\/webservice/g"   {}
 
 
 查询： ls grains.perf_* | xargs -I {} grep xxd_configure {}
        ls grains.perf_* | xargs -I {} sed -i "s/perf_/xn\//g"  {}
        ls grains.perf_* | xargs -I {} sed "s/v6_/v6\//g" {}
		
 查询连接到redis的服务器
 netstat  -antup | grep redis-server | grep -v LISTEN  | awk '{print $5}'|cut -d ":"  -f -1 | xargs -I {} grep {} /tmp/work_memo.txt
 
 
[root@centos7-laptop ~]# ansible product*tomcat  -m shell -a "mount" |grep -B 20 share   | grep "product\|share"
product_v6_pro01_v6_front01_tomcat | SUCCESS | rc=0 >>
192.168.60.34:/vx/XINXINDAI_FS/share on /share type nfs (rw,addr=192.168.60.34)
product_v6_pro02_v6_front02_tomcat | SUCCESS | rc=0 >>
192.168.60.34:/vx/XINXINDAI_FS/share on /share type nfs (rw,addr=192.168.60.34)
product_v6_pro03-v6_front03_tomcat | SUCCESS | rc=0 >>
192.168.60.34:/vx/XINXINDAI_FS/share on /share type nfs (rw,addr=192.168.60.34)
product_v6_pro01_v6_webservice01_tomcat | SUCCESS | rc=0 >>
192.168.60.34:/vx/XINXINDAI_FS/share on /share type nfs (rw,addr=192.168.60.34)
product_v6_pro02_v6_webservice02_tomcat | SUCCESS | rc=0 >>
192.168.60.34:/vx/XINXINDAI_FS/share on /share type nfs (rw,addr=192.168.60.34)
product_v6_pro03-v6_webservice03_tomcat | SUCCESS | rc=0 >>
192.168.60.34:/vx/XINXINDAI_FS/share on /share type nfs (rw,addr=192.168.60.34)
product-v6_pro01_v6_admin01_tomcat | SUCCESS | rc=0 >>
192.168.60.34:/vx/XINXINDAI_FS/share on /share type nfs (rw,addr=192.168.60.34)
product-v6_pro02_v6_admin02_tomcat | SUCCESS | rc=0 >>
192.168.60.34:/vx/XINXINDAI_FS/share on /share type nfs (rw,addr=192.168.60.34


scp *  root@192.168.38.10:/opt/ci/packages


=================================================
[yxaccount@salt ~]$  sudo  salt -L  "$minion_id"    cmd.run "mount | grep 60.34 ;cat /etc/salt/grains|grep 'imag' "
v6_nginx01:
    192.168.60.34:/vx/XINXINDAI_FS/sitemap on /usr/local/nginx/html/sitemap type nfs (rw,vers=3,addr=192.168.60.34)
    192.168.60.34:/vx/XINXINDAI_FS/download on /usr/local/nginx/html/static/download type nfs (rw,vers=3,addr=192.168.60.34)
    192.168.60.34:/vx/XINXINDAI_FS/v6_admin/image on /usr/local/nginx/html/static/admin/image type nfs (rw,vers=3,addr=192.168.60.34)
    192.168.60.34:/vx/XINXINDAI_FS/v6_front/image on /usr/local/nginx/html/static/image type nfs (rw,vers=3,addr=192.168.60.34)
    image_dir: /usr/local/nginx/html/static/image
    admin_image_dir: /usr/local/nginx/html/static/admin/image
    storage_image_dir: /volume1/v6/v6_front/image
    storage_admin_image_dir: /volume1/v6/v6_admin/image
v6_nginx02:
    192.168.60.34:/vx/XINXINDAI_FS/sitemap on /usr/local/nginx/html/sitemap type nfs (rw,vers=3,addr=192.168.60.34)
    192.168.60.34:/vx/XINXINDAI_FS/download on /usr/local/nginx/html/static/download type nfs (rw,vers=3,addr=192.168.60.34)
    192.168.60.34:/vx/XINXINDAI_FS/v6_admin/image on /usr/local/nginx/html/static/admin/image type nfs (rw,vers=3,addr=192.168.60.34)
    192.168.60.34:/vx/XINXINDAI_FS/v6_front/image on /usr/local/nginx/html/static/image type nfs (rw,vers=3,addr=192.168.60.34)
    image_dir: /usr/local/nginx/html/static/image
    admin_image_dir: /usr/local/nginx/html/static/admin/image
    storage_image_dir: /volume1/v6/v6_front/image
    storage_admin_image_dir: /volume1/v6/v6_admin/image
v6_front02:
    192.168.60.34:/vx/XINXINDAI_FS/share on /share type nfs (rw,addr=192.168.60.34)
    192.168.60.34:/vx/XINXINDAI_FS/v6_front/image on /opt/webserver/v6_tomcat/webapps/ROOT/static/image type nfs (rw,vers=3,addr=192.168.60.34)
    192.168.60.34:/vx/XINXINDAI_FS/v6_admin/image on /opt/webserver/v6_tomcat/webapps/ROOT/static/admin/image type nfs (rw,vers=3,addr=192.168.60.34)
    image_dir: /opt/webserver/v6_tomcat/webapps/ROOT/static/image
    admin_image_dir: /opt/webserver/v6_tomcat/webapps/ROOT/static/admin/image
    storage_image_dir: /volume1/v6/v6_front/image
    storage_admin_image_dir: /volume1/v6/v6_admin/image
v6_webservice01:
    192.168.60.34:/vx/XINXINDAI_FS/share on /share type nfs (rw,addr=192.168.60.34)
v6_webservice03:
    192.168.60.34:/vx/XINXINDAI_FS/share on /share type nfs (rw,addr=192.168.60.34)
v6_tradew02:
v6_tradew01:
v6_front03:
    192.168.60.34:/vx/XINXINDAI_FS/share on /share type nfs (rw,addr=192.168.60.34)
    192.168.60.34:/vx/XINXINDAI_FS/v6_front/image on /opt/webserver/v6_tomcat/webapps/ROOT/static/image type nfs (rw,vers=3,addr=192.168.60.34)
    192.168.60.34:/vx/XINXINDAI_FS/v6_admin/image on /opt/webserver/v6_tomcat/webapps/ROOT/static/admin/image type nfs (rw,vers=3,addr=192.168.60.34)
    image_dir: /opt/webserver/v6_tomcat/webapps/ROOT/static/image
    admin_image_dir: /opt/webserver/v6_tomcat/webapps/ROOT/static/admin/image
    storage_image_dir: /volume1/v6/v6_front/image
    storage_admin_image_dir: /volume1/v6/v6_admin/image
v6_webservice02:
    192.168.60.34:/vx/XINXINDAI_FS/share on /share type nfs (rw,addr=192.168.60.34)
v6_admin02:
    192.168.60.34:/vx/XINXINDAI_FS/share on /share type nfs (rw,addr=192.168.60.34)
    192.168.60.34:/vx/XINXINDAI_FS/v6_admin/images on /opt/webserver/v6_tomcat/webapps/xxdai_sys_admin/images type nfs (rw,vers=3,addr=192.168.60.34)
    192.168.60.34:/vx/XINXINDAI_FS/v6_admin/image on /opt/webserver/v6_tomcat/webapps/xxdai_sys_admin/image type nfs (rw,vers=3,addr=192.168.60.34)
    admin_image_dir: /opt/webserver/v6_tomcat/webapps/xxdai_sys_admin/image
    admin_images_dir: /opt/webserver/v6_tomcat/webapps/xxdai_sys_admin/images
    storage_admin_image_dir: /volume1/v6/v6_admin/image
    storage_admin_images_dir: /volume1/v6/v6_admin/images
v6_admin01:
    192.168.60.34:/vx/XINXINDAI_FS/share on /share type nfs (rw,addr=192.168.60.34)
    192.168.60.34:/vx/XINXINDAI_FS/v6_admin/images on /opt/webserver/v6_tomcat/webapps/xxdai_sys_admin/images type nfs (rw,vers=3,addr=192.168.60.34)
    192.168.60.34:/vx/XINXINDAI_FS/v6_admin/image on /opt/webserver/v6_tomcat/webapps/xxdai_sys_admin/image type nfs (rw,vers=3,addr=192.168.60.34)
    admin_image_dir: /opt/webserver/v6_tomcat/webapps/xxdai_sys_admin/image
    admin_images_dir: /opt/webserver/v6_tomcat/webapps/xxdai_sys_admin/images
    storage_admin_image_dir: /volume1/v6/v6_admin/image
    storage_admin_images_dir: /volume1/v6/v6_admin/images
v6_front01:
    192.168.60.34:/vx/XINXINDAI_FS/share on /share type nfs (rw,addr=192.168.60.34)
    192.168.60.34:/vx/XINXINDAI_FS/v6_front/image on /opt/webserver/v6_tomcat/webapps/ROOT/static/image type nfs (rw,vers=3,addr=192.168.60.34)
    192.168.60.34:/vx/XINXINDAI_FS/v6_admin/image on /opt/webserver/v6_tomcat/webapps/ROOT/static/admin/image type nfs (rw,vers=3,addr=192.168.60.34)
    image_dir: /opt/webserver/v6_tomcat/webapps/ROOT/static/image
    admin_image_dir: /opt/webserver/v6_tomcat/webapps/ROOT/static/admin/image
    storage_image_dir: /volume1/v6/v6_front/image
    storage_admin_image_dir: /volume1/v6/v6_admin/image
v6_batch02:
    192.168.60.34:/vx/XINXINDAI_FS/sitemap on /static/data/sitemap type nfs (rw,addr=192.168.60.34)
v6_tradew03:
v6_batch01:
    192.168.60.34:/vx/XINXINDAI_FS/sitemap on /static/data/sitemap type nfs (rw,addr=192.168.60.34)
v6_nginx03:
    192.168.60.34:/vx/XINXINDAI_FS/sitemap on /usr/local/nginx/html/sitemap type nfs (rw,vers=3,addr=192.168.60.34)
    192.168.60.34:/vx/XINXINDAI_FS/download on /usr/local/nginx/html/static/download type nfs (rw,vers=3,addr=192.168.60.34)
    192.168.60.34:/vx/XINXINDAI_FS/v6_admin/image on /usr/local/nginx/html/static/admin/image type nfs (rw,vers=3,addr=192.168.60.34)
    192.168.60.34:/vx/XINXINDAI_FS/v6_front/image on /usr/local/nginx/html/static/image type nfs (rw,vers=3,addr=192.168.60.34)
    image_dir: /usr/local/nginx/html/static/image
    admin_image_dir: /usr/local/nginx/html/static/admin/image
    storage_image_dir: /volume1/v6/v6_front/image
    storage_admin_image_dir: /volume1/v6/v6_admin/image
v6_webapp01:
    192.168.60.34:/vx/XINXINDAI_FS/v6_front/image on /opt/webserver/v6_tomcat/webapps/m/static/image type nfs (rw,vers=3,addr=192.168.60.34)
    image_dir: /opt/webserver/v6_tomcat/webapps/m/static/image
    storage_image_dir: /volume1/v6/v6_front/image
	
v6_mobile01:
    192.168.60.34:/vx/XINXINDAI_FS/v6_front/image on /opt/webserver/v6_tomcat/webapps/v5_mobile/static/image type nfs (rw,vers=3,addr=192.168.60.34)
    192.168.60.34:/vx/XINXINDAI_FS/v6_admin/image on /opt/webserver/v6_tomcat/webapps/v5_mobile/static/admin/image type nfs (rw,vers=3,addr=192.168.60.34)
    image_dir: /opt/webserver/v6_tomcat/webapps/v5_mobile/static/image
    admin_image_dir: /opt/webserver/v6_tomcat/webapps/v5_mobile/static/admin/image
    storage_image_dir: /volume1/v6/v6_front/image
    storage_admin_image_dir: /volume1/v6/v6_admin/image
+--------------------+-----------+
| Database           | Size (MB) |
+--------------------+-----------+
| airpal             |      0.80 |
| amon               |      4.61 |
| dashboard          |      2.94 |
| dashboard_dev      |    351.49 |
| dashboard_stage    |   2851.89 |
| dashboard_test     |   3047.10 |
| hive               |     55.41 |
| hue                |      4.42 |
| information_schema |      0.01 |
| mysql              |      0.66 |
| oozie              |     21.05 |
| performance_schema |      0.00 |
| scm                |     24.31 |
| zoo                |    544.58 |
+--------------------+-----------+

mvn deploy:deploy-file  -DgroupId=com.xxdai  -DartifactId=xxdai-utils  -Dversion=1.0   -DgeneratePom=false  -Dpackaging=jar -DrepositoryId=nexus "-Durl=http://192.168.31.178:8081/repository/xxdai_release"   -DpomFile=/tmp/xxdai_release/com/xxdai/xxdai-utils/1.0/xxdai-utils-1.0.pom   -Dfile=/tmp/xxdai_release/com/xxdai/xxdai-utils/1.0/xxdai-utils-1.0.jar
mvn deploy:deploy-file  -DgroupId=com.xxdai  -DartifactId=v6_flow  -Dversion=1.0   -DgeneratePom=false  -Dpackaging=jar -DrepositoryId=nexus "-Durl=http://192.168.31.178:8081/repository/xxdai_release"   -DpomFile=/tmp/xxdai_release/com/xxdai/v6_flow/1.0/v6_flow-1.0.pom   -Dfile=/tmp/xxdai_release/com/xxdai/v6_flow/1.0/v6_flow-1.0.jar
mvn deploy:deploy-file  -DgroupId=com.xxdai  -DartifactId=xxdai-appframe  -Dversion=1.2   -DgeneratePom=false  -Dpackaging=jar -DrepositoryId=nexus "-Durl=http://192.168.31.178:8081/repository/xxdai_release"   -DpomFile=/tmp/xxdai_release/com/xxdai/xxdai-appframe/1.2/xxdai-appframe-1.2.pom   -Dfile=/tmp/xxdai_release/com/xxdai/xxdai-appframe/1.2/xxdai-appframe-1.2.jar
mvn deploy:deploy-file  -DgroupId=com.xxdai  -DartifactId=xxdai-dbutils  -Dversion=1.0   -DgeneratePom=false  -Dpackaging=jar -DrepositoryId=nexus "-Durl=http://192.168.31.178:8081/repository/xxdai_release"   -DpomFile=/tmp/xxdai_release/com/xxdai/xxdai-dbutils/1.0/xxdai-dbutils-1.0.pom  -Dfile=/tmp/xxdai_release/com/xxdai/xxdai-dbutils/1.0/xxdai-dbutils-1.0.jar
mvn deploy:deploy-file  -DgroupId=com.xxdai  -DartifactId=oa_dynamicode    -Dversion=1.3  -DgeneratePom=false  -Dpackaging=jar -DrepositoryId=nexus "-Durl=http://192.168.31.178:8081/repository/xxdai_release"   -DpomFile=/tmp/xxdai_release/com/xxdai/oa_dynamicode/1.3/oa_dynamicode-1.3.pom    -Dfile=/tmp/xxdai_release/com/xxdai/oa_dynamicode/1.3/oa_dynamicode-1.3.jar
mvn deploy:deploy-file  -DgroupId=com.oracle  -DartifactId=ojdbc6_g    -Dversion=11.2  -DgeneratePom=false  -Dpackaging=jar -DrepositoryId=nexus "-Durl=http://192.168.31.178:8081/repository/xxdai_release"   -DpomFile=/tmp/xxdai_release/com/oracle/ojdbc6_g/11.2/ojdbc6_g-11.2.pom    -Dfile=/tmp/xxdai_release/com/oracle/ojdbc6_g/11.2/ojdbc6_g-11.2.jar
mvn deploy:deploy-file  -DgroupId=com.cloopen  -DartifactId=ccp_rest_sdk_java    -Dversion=2.6  -DgeneratePom=false  -Dpackaging=jar -DrepositoryId=nexus "-Durl=http://192.168.31.178:8081/repository/xxdai_release"   -DpomFile=/tmp/xxdai_release/com/cloopen/ccp_rest_sdk_java/2.6/ccp_rest_sdk_java-2.6.pom    -Dfile=/tmp/xxdai_release/com/cloopen/ccp_rest_sdk_java/2.6/ccp_rest_sdk_java-2.6.jar


mvn deploy:deploy-file  -DgroupId=com.xxdai  -DartifactId=xxdai-utils  -Dversion=1.1-SNAPSHOT   -DgeneratePom=false  -Dpackaging=jar -DrepositoryId=nexus "-Durl=http://192.168.31.178:8081/repository/xxdai_snapshot"   -DpomFile=/tmp/xxdai_snapshot/com/xxdai/xxdai-utils/1.1-SNAPSHOT/xxdai-utils-1.1.pom   -Dfile=/tmp/xxdai_snapshot/com/xxdai/xxdai-utils/1.1-SNAPSHOT/xxdai-utils-1.1.jar
mvn deploy:deploy-file  -DgroupId=com.xxdai  -DartifactId=xxdai-dbutils      -Dversion=1.1-SNAPSHOT   -DgeneratePom=false  -Dpackaging=jar -DrepositoryId=nexus "-Durl=http://192.168.31.178:8081/repository/xxdai_snapshot"   -DpomFile=/tmp/xxdai_snapshot/com/xxdai/xxdai-dbutils/1.1-SNAPSHOT/xxdai-dbutils-1.1-20150629.080248-1.pom   -Dfile=/tmp/xxdai_snapshot/com/xxdai/xxdai-dbutils/1.1-SNAPSHOT/xxdai-dbutils-1.1-20150629.080248-1.jar
mvn deploy:deploy-file  -DgroupId=com.xxdai  -DartifactId=xxdai-appframe    -Dversion=1.2.5-SNAPSHOT   -DgeneratePom=false  -Dpackaging=jar -DrepositoryId=nexus "-Durl=http://192.168.31.178:8081/repository/xxdai_snapshot"   -DpomFile=/tmp/xxdai_snapshot/com/xxdai/xxdai-appframe/1.2.5-SNAPSHOT/xxdai-appframe-1.2.5-20160405.100429-5.pom   -Dfile=/tmp/xxdai_snapshot/com/xxdai/xxdai-appframe/1.2.5-SNAPSHOT/xxdai-appframe-1.2.5-20160405.100429-5.jar
 mvn deploy:deploy-file  -DgroupId=com.xxdai  -DartifactId=xxdai-appframe    -Dversion=1.2.4-SNAPSHOT   -DgeneratePom=false  -Dpackaging=jar -DrepositoryId=nexus "-Durl=http://192.168.31.178:8081/repository/xxdai_snapshot"   -DpomFile=/tmp/xxdai_snapshot/com/xxdai/xxdai-appframe/1.2.4-SNAPSHOT/xxdai-appframe-1.2.4-20160105.055001-3.pom    -Dfile=/tmp/xxdai_snapshot/com/xxdai/xxdai-appframe/1.2.4-SNAPSHOT/xxdai-appframe-1.2.4-20160105.055001-3.jar
 
 
mvn deploy:deploy-file  -DgroupId=com.xxdai  -DartifactId=v6_flow    -Dversion=1.1-SNAPSHOT   -DgeneratePom=false  -Dpackaging=jar -DrepositoryId=nexus "-Durl=http://192.168.31.178:8081/repository/xxdai_snapshot"   -DpomFile=/tmp/xxdai_snapshot/com/xxdai/v6_flow/1.1-SNAPSHOT/v6_flow-1.1-20150629.080333-1.pom    -Dfile=/tmp/xxdai_snapshot/com/xxdai/v6_flow/1.1-SNAPSHOT/v6_flow-1.1-20150629.080333-1.jar

curl -v -u admin:admin123 --upload-file  /tmp/xxdai_snapshot/com/xxdai/v6_parent/1.2.4-SNAPSHOT/v6_parent-1.2.4-SNAPSHOT.pom  http://192.168.31.178:8081/repository/xxdai_snapshot/com/xxdai/v6_parent/1.2.4-SNAPSHOT/v6_parent-1.2.4-SNAPSHOT.pom
curl -v -u admin:admin123 --upload-file  /tmp/xxdai_snapshot/com/xxdai/v6_parent/1.2.5-SNAPSHOT/v6_parent-1.2.5-20160504.054526-3.pom   http://192.168.31.178:8081/repository/xxdai_snapshot/com/xxdai/v6_parent/1.2.5-SNAPSHOT/v6_parent-1.2.5-SNAPSHOT.pom
curl -v -u admin:admin123 --upload-file  ./xxdai_snapshot/com/xxdai/v6_parent/1.2.3-SNAPSHOT/v6_parent-1.2.3-20151222.022835-1.pom    http://192.168.31.178:8081/repository/xxdai_snapshot/com/xxdai/v6_parent/1.2.3-SNAPSHOT/v6_parent-1.2.3-SNAPSHOT.pom

curl -v -u admin:admin123 --upload-file  /tmp/xxdai_release/com/xxdai/v6_third_lib/1.1/v6_third_lib-1.1.pom  http://192.168.31.178:8081/repository/xxdai_release/com/xxdai/v6_third_lib/1.1/v6_third_lib-1.1.pom
curl -v -u admin:admin123 --upload-file  /tmp/xxdai_release/com/xxdai/v6_third_lib/1.0/v6_third_lib-1.0.pom    http://192.168.31.178:8081/repository/xxdai_release/com/xxdai/v6_third_lib/1.0/v6_third_lib-1.0.pom


rsync  -avh   ./admin/          192.168.110.102:/srv/salt/xinxindai_tomcat/files/v6_admin/        
rsync  -avh   ./batch/          192.168.110.102:/srv/salt/xinxindai_tomcat/files/v6_batch/        
rsync  -avh   ./front/          192.168.110.102:/srv/salt/xinxindai_tomcat/files/v6_front/        
rsync  -avh   ./partener/       192.168.110.102:/srv/salt/xinxindai_tomcat/files/v6_partener/     
rsync  -avh   ./tradews/        192.168.110.102:/srv/salt/xinxindai_tomcat/files/v6_tradews/      
rsync  -avh   ./webservice/     192.168.110.102:/srv/salt/xinxindai_tomcat/files/v6_webservice/   


